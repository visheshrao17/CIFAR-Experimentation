{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/visheshrao17/CIFAR-Experimentation-/blob/main/CNN_CIAFR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b503c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eceee78c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c832c9e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb5923f",
   "metadata": {
    "id": "eeb5923f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and transformations defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Libraries imported and transformations defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c6b1fac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c6b1fac",
    "outputId": "89e76876-d973-49c6-9c21-756190b1b000"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:01<00:00, 88.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 training dataset loaded with 10000 samples.\n",
      "CIFAR-10 test dataset loaded with 2000 samples.\n",
      "DataLoader instances created with batch size 64.\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "train_subset_size = 10000\n",
    "test_subset_size = 2000\n",
    "\n",
    "# Create a subset of the training dataset\n",
    "train_indices = torch.randperm(len(trainset))[:train_subset_size]\n",
    "train_subset = Subset(trainset, train_indices)\n",
    "\n",
    "# Create a subset of the test dataset\n",
    "test_indices = torch.randperm(len(testset))[:test_subset_size]\n",
    "test_subset = Subset(testset, test_indices)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoader instances\n",
    "trainloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"CIFAR-10 training dataset loaded with {len(train_subset)} samples.\")\n",
    "print(f\"CIFAR-10 test dataset loaded with {len(test_subset)} samples.\")\n",
    "print(f\"DataLoader instances created with batch size {batch_size}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "FCwnzclAdkDv",
   "metadata": {
    "id": "FCwnzclAdkDv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model architecture defined.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a Convolutional Neural Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "print(\"CNN model architecture defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43cb18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation functions defined.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        outputs = model(inputs) \n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward()  \n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()  \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "print(\"Training and validation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e26b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "--- Experimenting with LR: 0.01, Batch Size: 32, Epochs: 5 ---\n",
      "Epoch 1/5 | Train Loss: 2.1406, Train Acc: 0.1984 | Val Loss: 1.9189, Val Acc: 0.2840\n",
      "Epoch 2/5 | Train Loss: 1.7814, Train Acc: 0.3357 | Val Loss: 1.6330, Val Acc: 0.3900\n",
      "Epoch 3/5 | Train Loss: 1.5805, Train Acc: 0.4202 | Val Loss: 1.5990, Val Acc: 0.4225\n",
      "Epoch 4/5 | Train Loss: 1.4593, Train Acc: 0.4636 | Val Loss: 1.4839, Val Acc: 0.4685\n",
      "Epoch 5/5 | Train Loss: 1.3847, Train Acc: 0.4968 | Val Loss: 1.4626, Val Acc: 0.4750\n",
      "\n",
      "--- Experimenting with LR: 0.01, Batch Size: 32, Epochs: 10 ---\n",
      "Epoch 1/10 | Train Loss: 2.1989, Train Acc: 0.1627 | Val Loss: 1.9710, Val Acc: 0.2690\n",
      "Epoch 2/10 | Train Loss: 1.8245, Train Acc: 0.3199 | Val Loss: 1.6676, Val Acc: 0.3655\n",
      "Epoch 3/10 | Train Loss: 1.5881, Train Acc: 0.4179 | Val Loss: 1.5921, Val Acc: 0.4145\n",
      "Epoch 4/10 | Train Loss: 1.4716, Train Acc: 0.4590 | Val Loss: 1.4476, Val Acc: 0.4675\n",
      "Epoch 5/10 | Train Loss: 1.3840, Train Acc: 0.4944 | Val Loss: 1.5845, Val Acc: 0.4340\n",
      "Epoch 6/10 | Train Loss: 1.2782, Train Acc: 0.5358 | Val Loss: 1.3648, Val Acc: 0.5275\n",
      "Epoch 7/10 | Train Loss: 1.2096, Train Acc: 0.5630 | Val Loss: 1.3844, Val Acc: 0.5150\n",
      "Epoch 8/10 | Train Loss: 1.1048, Train Acc: 0.6003 | Val Loss: 1.4082, Val Acc: 0.4990\n",
      "Epoch 9/10 | Train Loss: 1.0376, Train Acc: 0.6269 | Val Loss: 1.6302, Val Acc: 0.4935\n",
      "Epoch 10/10 | Train Loss: 0.9756, Train Acc: 0.6505 | Val Loss: 1.4401, Val Acc: 0.5175\n",
      "\n",
      "--- Experimenting with LR: 0.01, Batch Size: 64, Epochs: 5 ---\n",
      "Epoch 1/5 | Train Loss: 2.2705, Train Acc: 0.1459 | Val Loss: 2.0944, Val Acc: 0.2360\n",
      "Epoch 2/5 | Train Loss: 1.9633, Train Acc: 0.2650 | Val Loss: 1.9013, Val Acc: 0.2945\n",
      "Epoch 3/5 | Train Loss: 1.7347, Train Acc: 0.3614 | Val Loss: 1.6625, Val Acc: 0.3905\n",
      "Epoch 4/5 | Train Loss: 1.6125, Train Acc: 0.4079 | Val Loss: 1.5672, Val Acc: 0.4470\n",
      "Epoch 5/5 | Train Loss: 1.4979, Train Acc: 0.4512 | Val Loss: 1.5031, Val Acc: 0.4490\n",
      "\n",
      "--- Experimenting with LR: 0.01, Batch Size: 64, Epochs: 10 ---\n",
      "Epoch 1/10 | Train Loss: 2.2735, Train Acc: 0.1341 | Val Loss: 2.1255, Val Acc: 0.2020\n",
      "Epoch 2/10 | Train Loss: 1.9619, Train Acc: 0.2847 | Val Loss: 1.8299, Val Acc: 0.3495\n",
      "Epoch 3/10 | Train Loss: 1.7413, Train Acc: 0.3578 | Val Loss: 1.7198, Val Acc: 0.3770\n",
      "Epoch 4/10 | Train Loss: 1.5920, Train Acc: 0.4200 | Val Loss: 1.5362, Val Acc: 0.4335\n",
      "Epoch 5/10 | Train Loss: 1.5015, Train Acc: 0.4520 | Val Loss: 1.5290, Val Acc: 0.4530\n",
      "Epoch 6/10 | Train Loss: 1.4367, Train Acc: 0.4757 | Val Loss: 1.5028, Val Acc: 0.4680\n",
      "Epoch 7/10 | Train Loss: 1.3647, Train Acc: 0.5082 | Val Loss: 1.3844, Val Acc: 0.4975\n",
      "Epoch 8/10 | Train Loss: 1.3036, Train Acc: 0.5323 | Val Loss: 1.4132, Val Acc: 0.4905\n",
      "Epoch 9/10 | Train Loss: 1.2270, Train Acc: 0.5581 | Val Loss: 1.4514, Val Acc: 0.4890\n",
      "Epoch 10/10 | Train Loss: 1.1776, Train Acc: 0.5727 | Val Loss: 1.3538, Val Acc: 0.5335\n",
      "\n",
      "--- Experimenting with LR: 0.001, Batch Size: 32, Epochs: 5 ---\n",
      "Epoch 1/5 | Train Loss: 2.3049, Train Acc: 0.0995 | Val Loss: 2.2992, Val Acc: 0.1415\n",
      "Epoch 2/5 | Train Loss: 2.2983, Train Acc: 0.1249 | Val Loss: 2.2939, Val Acc: 0.1295\n",
      "Epoch 3/5 | Train Loss: 2.2865, Train Acc: 0.1390 | Val Loss: 2.2758, Val Acc: 0.1440\n",
      "Epoch 4/5 | Train Loss: 2.2267, Train Acc: 0.1769 | Val Loss: 2.1456, Val Acc: 0.2070\n",
      "Epoch 5/5 | Train Loss: 2.0909, Train Acc: 0.2296 | Val Loss: 2.0283, Val Acc: 0.2370\n",
      "\n",
      "--- Experimenting with LR: 0.001, Batch Size: 32, Epochs: 10 ---\n",
      "Epoch 1/10 | Train Loss: 2.3021, Train Acc: 0.1138 | Val Loss: 2.3006, Val Acc: 0.1320\n",
      "Epoch 2/10 | Train Loss: 2.2980, Train Acc: 0.1451 | Val Loss: 2.2961, Val Acc: 0.1115\n",
      "Epoch 3/10 | Train Loss: 2.2881, Train Acc: 0.1374 | Val Loss: 2.2766, Val Acc: 0.1615\n",
      "Epoch 4/10 | Train Loss: 2.2188, Train Acc: 0.2128 | Val Loss: 2.1062, Val Acc: 0.2490\n",
      "Epoch 5/10 | Train Loss: 2.0183, Train Acc: 0.2698 | Val Loss: 1.9582, Val Acc: 0.2880\n",
      "Epoch 6/10 | Train Loss: 1.9040, Train Acc: 0.3033 | Val Loss: 1.8421, Val Acc: 0.3190\n",
      "Epoch 7/10 | Train Loss: 1.8141, Train Acc: 0.3390 | Val Loss: 1.7679, Val Acc: 0.3450\n",
      "Epoch 8/10 | Train Loss: 1.7416, Train Acc: 0.3664 | Val Loss: 1.7062, Val Acc: 0.3780\n",
      "Epoch 9/10 | Train Loss: 1.6820, Train Acc: 0.3831 | Val Loss: 1.6652, Val Acc: 0.3830\n",
      "Epoch 10/10 | Train Loss: 1.6390, Train Acc: 0.4026 | Val Loss: 1.6298, Val Acc: 0.4045\n",
      "\n",
      "--- Experimenting with LR: 0.001, Batch Size: 64, Epochs: 5 ---\n",
      "Epoch 1/5 | Train Loss: 2.3057, Train Acc: 0.0998 | Val Loss: 2.3016, Val Acc: 0.1070\n",
      "Epoch 2/5 | Train Loss: 2.3036, Train Acc: 0.0998 | Val Loss: 2.3007, Val Acc: 0.1070\n",
      "Epoch 3/5 | Train Loss: 2.3020, Train Acc: 0.1003 | Val Loss: 2.2999, Val Acc: 0.1105\n",
      "Epoch 4/5 | Train Loss: 2.3004, Train Acc: 0.1110 | Val Loss: 2.2988, Val Acc: 0.1265\n",
      "Epoch 5/5 | Train Loss: 2.2985, Train Acc: 0.1110 | Val Loss: 2.2971, Val Acc: 0.1280\n",
      "\n",
      "--- Experimenting with LR: 0.001, Batch Size: 64, Epochs: 10 ---\n",
      "Epoch 1/10 | Train Loss: 2.3062, Train Acc: 0.1000 | Val Loss: 2.3033, Val Acc: 0.1070\n",
      "Epoch 2/10 | Train Loss: 2.3042, Train Acc: 0.0998 | Val Loss: 2.3023, Val Acc: 0.1070\n",
      "Epoch 3/10 | Train Loss: 2.3027, Train Acc: 0.0973 | Val Loss: 2.3013, Val Acc: 0.1065\n",
      "Epoch 4/10 | Train Loss: 2.3012, Train Acc: 0.0986 | Val Loss: 2.3002, Val Acc: 0.0935\n",
      "Epoch 5/10 | Train Loss: 2.2995, Train Acc: 0.0998 | Val Loss: 2.2986, Val Acc: 0.0975\n",
      "Epoch 6/10 | Train Loss: 2.2972, Train Acc: 0.0987 | Val Loss: 2.2959, Val Acc: 0.0940\n",
      "Epoch 7/10 | Train Loss: 2.2934, Train Acc: 0.1030 | Val Loss: 2.2909, Val Acc: 0.1070\n",
      "Epoch 8/10 | Train Loss: 2.2858, Train Acc: 0.1241 | Val Loss: 2.2798, Val Acc: 0.1365\n",
      "Epoch 9/10 | Train Loss: 2.2687, Train Acc: 0.1593 | Val Loss: 2.2542, Val Acc: 0.1830\n",
      "Epoch 10/10 | Train Loss: 2.2281, Train Acc: 0.1862 | Val Loss: 2.1929, Val Acc: 0.1890\n",
      "\n",
      "Best Validation Accuracy: 0.5335 with Hyperparameters: {'learning_rate': 0.01, 'batch_size': 64, 'num_epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define hyperparameters to experiment with\n",
    "learning_rates = [0.01, 0.001]\n",
    "batch_sizes = [32, 64]\n",
    "num_epochs_list = [5, 10]\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for epochs in num_epochs_list:\n",
    "            print(f\"\\n--- Experimenting with LR: {lr}, Batch Size: {bs}, Epochs: {epochs} ---\")\n",
    "\n",
    "            # Re-initialize model and optimizer for each experiment\n",
    "            model = Net().to(device)\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "            # Create new DataLoader instances with current batch size\n",
    "            trainloader_exp = DataLoader(train_subset, batch_size=bs, shuffle=True)\n",
    "            testloader_exp = DataLoader(test_subset, batch_size=bs, shuffle=False)\n",
    "\n",
    "            # Lists to store metrics for the current hyperparameter combination\n",
    "            current_train_losses = []\n",
    "            current_train_accuracies = []\n",
    "            current_val_losses = []\n",
    "            current_val_accuracies = []\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                # Train the model for one epoch\n",
    "                train_loss, train_acc = train_epoch(model, trainloader_exp, criterion, optimizer, device)\n",
    "                current_train_losses.append(train_loss)\n",
    "                current_train_accuracies.append(train_acc)\n",
    "\n",
    "                # Validate the model\n",
    "                val_loss, val_acc = validate_epoch(model, testloader_exp, criterion, device)\n",
    "                current_val_losses.append(val_loss)\n",
    "                current_val_accuracies.append(val_acc)\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            # Store results for this combination\n",
    "            results.append({\n",
    "                'learning_rate': lr,\n",
    "                'batch_size': bs,\n",
    "                'num_epochs': epochs,\n",
    "                'train_losses': current_train_losses,\n",
    "                'train_accuracies': current_train_accuracies,\n",
    "                'val_losses': current_val_losses,\n",
    "                'val_accuracies': current_val_accuracies\n",
    "            })\n",
    "\n",
    "            # Check if this model is the best performing one\n",
    "            if current_val_accuracies[-1] > best_val_accuracy:\n",
    "                best_val_accuracy = current_val_accuracies[-1]\n",
    "                best_hyperparameters = {\n",
    "                    'learning_rate': lr,\n",
    "                    'batch_size': bs,\n",
    "                    'num_epochs': epochs\n",
    "                }\n",
    "                # Optionally, save the best model state here\n",
    "                # torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "print(f\"\\nBest Validation Accuracy: {best_val_accuracy:.4f} with Hyperparameters: {best_hyperparameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da981ba3",
   "metadata": {},
   "source": [
    "## Baseline Model Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1619946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline Model Results (Without Data Augmentation) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bd7104e7-efb9-4616-b12c-b4d78f457c23\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Num Epochs</th>\n",
       "      <th>Final Val Accuracy</th>\n",
       "      <th>Final Val Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>1.4626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>1.4401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>1.5031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>1.3538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>2.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4045</td>\n",
       "      <td>1.6298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>2.2971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>2.1929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd7104e7-efb9-4616-b12c-b4d78f457c23')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-bd7104e7-efb9-4616-b12c-b4d78f457c23 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-bd7104e7-efb9-4616-b12c-b4d78f457c23');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Learning Rate  Batch Size  Num Epochs  Final Val Accuracy  Final Val Loss\n",
       "0          0.010          32           5              0.4750          1.4626\n",
       "1          0.010          32          10              0.5175          1.4401\n",
       "2          0.010          64           5              0.4490          1.5031\n",
       "3          0.010          64          10              0.5335          1.3538\n",
       "4          0.001          32           5              0.2370          2.0283\n",
       "5          0.001          32          10              0.4045          1.6298\n",
       "6          0.001          64           5              0.1280          2.2971\n",
       "7          0.001          64          10              0.1890          2.1929"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Validation Accuracy: 0.5335\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'batch_size': 64, 'num_epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary of baseline experiments (without augmentation)\n",
    "summary_data = []\n",
    "\n",
    "for res in results:\n",
    "    summary_data.append({\n",
    "        'Learning Rate': res['learning_rate'],\n",
    "        'Batch Size': res['batch_size'],\n",
    "        'Num Epochs': res['num_epochs'],\n",
    "        'Final Val Accuracy': res['val_accuracies'][-1],\n",
    "        'Final Val Loss': res['val_losses'][-1]\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n=== Baseline Model Results (Without Data Augmentation) ===\")\n",
    "display(summary_df.round(4))\n",
    "\n",
    "print(f\"\\nBest Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"Best Hyperparameters: {best_hyperparameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fb37c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
