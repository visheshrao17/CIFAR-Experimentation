{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visheshrao17/CIFAR-Experimentation-/blob/main/CNN_CIAFR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c832c9e",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eeb5923f",
      "metadata": {
        "id": "eeb5923f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported and transformations defined.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Define transformations for the dataset\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Libraries imported and transformations defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0c6b1fac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c6b1fac",
        "outputId": "89e76876-d973-49c6-9c21-756190b1b000"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:36<00:00, 4.68MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CIFAR-10 training dataset loaded with 5000 samples.\n",
            "CIFAR-10 test dataset loaded with 1000 samples.\n",
            "DataLoader instances created with batch size 64.\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "train_subset_size = 5000\n",
        "test_subset_size = 1000\n",
        "\n",
        "# Create a subset of the training dataset\n",
        "train_indices = torch.randperm(len(trainset))[:train_subset_size]\n",
        "train_subset = Subset(trainset, train_indices)\n",
        "\n",
        "# Create a subset of the test dataset\n",
        "test_indices = torch.randperm(len(testset))[:test_subset_size]\n",
        "test_subset = Subset(testset, test_indices)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Create DataLoader instances\n",
        "trainloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"CIFAR-10 training dataset loaded with {len(train_subset)} samples.\")\n",
        "print(f\"CIFAR-10 test dataset loaded with {len(test_subset)} samples.\")\n",
        "print(f\"DataLoader instances created with batch size {batch_size}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "FCwnzclAdkDv",
      "metadata": {
        "id": "FCwnzclAdkDv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN model architecture defined.\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a Convolutional Neural Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
        "        self.pool = nn.MaxPool2d(2, 2) \n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "        \n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10) \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "print(\"CNN model architecture defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d43cb18d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and validation functions defined.\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()  \n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  \n",
        "\n",
        "        outputs = model(inputs) \n",
        "        loss = criterion(outputs, labels) \n",
        "        loss.backward()  \n",
        "        optimizer.step() \n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "    \n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()  \n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():  \n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "print(\"Training and validation functions defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a9e26b3d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n",
            "--- Experimenting with LR: 0.01, Batch Size: 32, Epochs: 5 ---\n",
            "Epoch 1/5 | Train Loss: 2.2510, Train Acc: 0.1502 | Val Loss: 2.0745, Val Acc: 0.2090\n",
            "Epoch 2/5 | Train Loss: 2.0030, Train Acc: 0.2434 | Val Loss: 1.8768, Val Acc: 0.3080\n",
            "Epoch 3/5 | Train Loss: 1.8037, Train Acc: 0.3388 | Val Loss: 1.7442, Val Acc: 0.3360\n",
            "Epoch 4/5 | Train Loss: 1.6796, Train Acc: 0.3754 | Val Loss: 1.7101, Val Acc: 0.3630\n",
            "Epoch 5/5 | Train Loss: 1.5959, Train Acc: 0.4130 | Val Loss: 1.6061, Val Acc: 0.4110\n",
            "\n",
            "--- Experimenting with LR: 0.01, Batch Size: 32, Epochs: 10 ---\n",
            "Epoch 1/10 | Train Loss: 2.2999, Train Acc: 0.1078 | Val Loss: 2.2898, Val Acc: 0.1610\n",
            "Epoch 2/10 | Train Loss: 2.1179, Train Acc: 0.2306 | Val Loss: 1.9607, Val Acc: 0.2840\n",
            "Epoch 3/10 | Train Loss: 1.8868, Train Acc: 0.2910 | Val Loss: 1.8307, Val Acc: 0.3200\n",
            "Epoch 4/10 | Train Loss: 1.7265, Train Acc: 0.3662 | Val Loss: 1.7609, Val Acc: 0.3270\n",
            "Epoch 5/10 | Train Loss: 1.6276, Train Acc: 0.3968 | Val Loss: 1.6757, Val Acc: 0.3810\n",
            "Epoch 6/10 | Train Loss: 1.5278, Train Acc: 0.4346 | Val Loss: 1.6491, Val Acc: 0.4210\n",
            "Epoch 7/10 | Train Loss: 1.4471, Train Acc: 0.4680 | Val Loss: 1.5737, Val Acc: 0.4440\n",
            "Epoch 8/10 | Train Loss: 1.3738, Train Acc: 0.5024 | Val Loss: 1.6427, Val Acc: 0.4180\n",
            "Epoch 9/10 | Train Loss: 1.3054, Train Acc: 0.5220 | Val Loss: 1.5407, Val Acc: 0.4640\n",
            "Epoch 10/10 | Train Loss: 1.2163, Train Acc: 0.5590 | Val Loss: 1.5871, Val Acc: 0.4430\n",
            "\n",
            "--- Experimenting with LR: 0.01, Batch Size: 64, Epochs: 5 ---\n",
            "Epoch 1/5 | Train Loss: 2.2992, Train Acc: 0.1174 | Val Loss: 2.2883, Val Acc: 0.0980\n",
            "Epoch 2/5 | Train Loss: 2.2100, Train Acc: 0.1690 | Val Loss: 2.0868, Val Acc: 0.2460\n",
            "Epoch 3/5 | Train Loss: 2.0173, Train Acc: 0.2498 | Val Loss: 1.9354, Val Acc: 0.3000\n",
            "Epoch 4/5 | Train Loss: 1.8742, Train Acc: 0.3150 | Val Loss: 1.7953, Val Acc: 0.3380\n",
            "Epoch 5/5 | Train Loss: 1.7342, Train Acc: 0.3610 | Val Loss: 1.6585, Val Acc: 0.3960\n",
            "\n",
            "--- Experimenting with LR: 0.01, Batch Size: 64, Epochs: 10 ---\n",
            "Epoch 1/10 | Train Loss: 2.3020, Train Acc: 0.1058 | Val Loss: 2.2982, Val Acc: 0.0970\n",
            "Epoch 2/10 | Train Loss: 2.2851, Train Acc: 0.1594 | Val Loss: 2.2515, Val Acc: 0.1910\n",
            "Epoch 3/10 | Train Loss: 2.1431, Train Acc: 0.2188 | Val Loss: 2.0119, Val Acc: 0.2740\n",
            "Epoch 4/10 | Train Loss: 1.9552, Train Acc: 0.2828 | Val Loss: 1.8507, Val Acc: 0.3240\n",
            "Epoch 5/10 | Train Loss: 1.7903, Train Acc: 0.3342 | Val Loss: 1.7229, Val Acc: 0.3610\n",
            "Epoch 6/10 | Train Loss: 1.7190, Train Acc: 0.3626 | Val Loss: 1.8885, Val Acc: 0.3210\n",
            "Epoch 7/10 | Train Loss: 1.6522, Train Acc: 0.3822 | Val Loss: 1.5907, Val Acc: 0.4220\n",
            "Epoch 8/10 | Train Loss: 1.5883, Train Acc: 0.4158 | Val Loss: 1.7239, Val Acc: 0.3780\n",
            "Epoch 9/10 | Train Loss: 1.5283, Train Acc: 0.4438 | Val Loss: 1.6083, Val Acc: 0.4140\n",
            "Epoch 10/10 | Train Loss: 1.4901, Train Acc: 0.4564 | Val Loss: 1.5386, Val Acc: 0.4340\n",
            "\n",
            "--- Experimenting with LR: 0.001, Batch Size: 32, Epochs: 5 ---\n",
            "Epoch 1/5 | Train Loss: 2.3049, Train Acc: 0.0884 | Val Loss: 2.3059, Val Acc: 0.0920\n",
            "Epoch 2/5 | Train Loss: 2.3033, Train Acc: 0.1012 | Val Loss: 2.3043, Val Acc: 0.1080\n",
            "Epoch 3/5 | Train Loss: 2.3018, Train Acc: 0.1048 | Val Loss: 2.3028, Val Acc: 0.0970\n",
            "Epoch 4/5 | Train Loss: 2.3003, Train Acc: 0.1058 | Val Loss: 2.3010, Val Acc: 0.1210\n",
            "Epoch 5/5 | Train Loss: 2.2984, Train Acc: 0.1594 | Val Loss: 2.2986, Val Acc: 0.1570\n",
            "\n",
            "--- Experimenting with LR: 0.001, Batch Size: 32, Epochs: 10 ---\n",
            "Epoch 1/10 | Train Loss: 2.3041, Train Acc: 0.0838 | Val Loss: 2.3028, Val Acc: 0.1090\n",
            "Epoch 2/10 | Train Loss: 2.3018, Train Acc: 0.1126 | Val Loss: 2.3010, Val Acc: 0.1290\n",
            "Epoch 3/10 | Train Loss: 2.2990, Train Acc: 0.1412 | Val Loss: 2.2980, Val Acc: 0.1420\n",
            "Epoch 4/10 | Train Loss: 2.2942, Train Acc: 0.1276 | Val Loss: 2.2922, Val Acc: 0.1160\n",
            "Epoch 5/10 | Train Loss: 2.2832, Train Acc: 0.1420 | Val Loss: 2.2764, Val Acc: 0.1450\n",
            "Epoch 6/10 | Train Loss: 2.2532, Train Acc: 0.1532 | Val Loss: 2.2388, Val Acc: 0.1740\n",
            "Epoch 7/10 | Train Loss: 2.2125, Train Acc: 0.1774 | Val Loss: 2.1989, Val Acc: 0.1970\n",
            "Epoch 8/10 | Train Loss: 2.1715, Train Acc: 0.2060 | Val Loss: 2.1566, Val Acc: 0.2270\n",
            "Epoch 9/10 | Train Loss: 2.1292, Train Acc: 0.2278 | Val Loss: 2.1109, Val Acc: 0.2470\n",
            "Epoch 10/10 | Train Loss: 2.0858, Train Acc: 0.2382 | Val Loss: 2.0615, Val Acc: 0.2630\n",
            "\n",
            "--- Experimenting with LR: 0.001, Batch Size: 64, Epochs: 5 ---\n",
            "Epoch 1/5 | Train Loss: 2.3032, Train Acc: 0.1016 | Val Loss: 2.3020, Val Acc: 0.0970\n",
            "Epoch 2/5 | Train Loss: 2.3014, Train Acc: 0.1030 | Val Loss: 2.3005, Val Acc: 0.0990\n",
            "Epoch 3/5 | Train Loss: 2.2995, Train Acc: 0.1112 | Val Loss: 2.2989, Val Acc: 0.1170\n",
            "Epoch 4/5 | Train Loss: 2.2973, Train Acc: 0.1374 | Val Loss: 2.2969, Val Acc: 0.1350\n",
            "Epoch 5/5 | Train Loss: 2.2947, Train Acc: 0.1462 | Val Loss: 2.2944, Val Acc: 0.1370\n",
            "\n",
            "--- Experimenting with LR: 0.001, Batch Size: 64, Epochs: 10 ---\n",
            "Epoch 1/10 | Train Loss: 2.3045, Train Acc: 0.0912 | Val Loss: 2.3049, Val Acc: 0.0890\n",
            "Epoch 2/10 | Train Loss: 2.3033, Train Acc: 0.1044 | Val Loss: 2.3038, Val Acc: 0.1220\n",
            "Epoch 3/10 | Train Loss: 2.3021, Train Acc: 0.1314 | Val Loss: 2.3027, Val Acc: 0.1300\n",
            "Epoch 4/10 | Train Loss: 2.3008, Train Acc: 0.1382 | Val Loss: 2.3013, Val Acc: 0.1290\n",
            "Epoch 5/10 | Train Loss: 2.2992, Train Acc: 0.1368 | Val Loss: 2.2998, Val Acc: 0.1340\n",
            "Epoch 6/10 | Train Loss: 2.2973, Train Acc: 0.1420 | Val Loss: 2.2977, Val Acc: 0.1340\n",
            "Epoch 7/10 | Train Loss: 2.2949, Train Acc: 0.1500 | Val Loss: 2.2950, Val Acc: 0.1480\n",
            "Epoch 8/10 | Train Loss: 2.2912, Train Acc: 0.1644 | Val Loss: 2.2908, Val Acc: 0.1750\n",
            "Epoch 9/10 | Train Loss: 2.2853, Train Acc: 0.1772 | Val Loss: 2.2838, Val Acc: 0.1810\n",
            "Epoch 10/10 | Train Loss: 2.2753, Train Acc: 0.1674 | Val Loss: 2.2712, Val Acc: 0.1610\n",
            "\n",
            "Best Validation Accuracy: 0.4430 with Hyperparameters: {'learning_rate': 0.01, 'batch_size': 32, 'num_epochs': 10}\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define hyperparameters to experiment with\n",
        "learning_rates = [0.01, 0.001]\n",
        "batch_sizes = [32, 64]\n",
        "num_epochs_list = [5, 10]\n",
        "\n",
        "best_val_accuracy = 0.0\n",
        "best_hyperparameters = {}\n",
        "\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        for epochs in num_epochs_list:\n",
        "            print(f\"\\n--- Experimenting with LR: {lr}, Batch Size: {bs}, Epochs: {epochs} ---\")\n",
        "\n",
        "            # Re-initialize model and optimizer for each experiment\n",
        "            model = Net().to(device)\n",
        "            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "            # Create new DataLoader instances with current batch size\n",
        "            trainloader_exp = DataLoader(train_subset, batch_size=bs, shuffle=True)\n",
        "            testloader_exp = DataLoader(test_subset, batch_size=bs, shuffle=False)\n",
        "\n",
        "            # Lists to store metrics for the current hyperparameter combination\n",
        "            current_train_losses = []\n",
        "            current_train_accuracies = []\n",
        "            current_val_losses = []\n",
        "            current_val_accuracies = []\n",
        "            \n",
        "            for epoch in range(epochs):\n",
        "                # Train the model for one epoch\n",
        "                train_loss, train_acc = train_epoch(model, trainloader_exp, criterion, optimizer, device)\n",
        "                current_train_losses.append(train_loss)\n",
        "                current_train_accuracies.append(train_acc)\n",
        "\n",
        "                # Validate the model\n",
        "                val_loss, val_acc = validate_epoch(model, testloader_exp, criterion, device)\n",
        "                current_val_losses.append(val_loss)\n",
        "                current_val_accuracies.append(val_acc)\n",
        "\n",
        "                print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "            \n",
        "            # Store results for this combination\n",
        "            results.append({\n",
        "                'learning_rate': lr,\n",
        "                'batch_size': bs,\n",
        "                'num_epochs': epochs,\n",
        "                'train_losses': current_train_losses,\n",
        "                'train_accuracies': current_train_accuracies,\n",
        "                'val_losses': current_val_losses,\n",
        "                'val_accuracies': current_val_accuracies\n",
        "            })\n",
        "\n",
        "            # Check if this model is the best performing one\n",
        "            if current_val_accuracies[-1] > best_val_accuracy:\n",
        "                best_val_accuracy = current_val_accuracies[-1]\n",
        "                best_hyperparameters = {\n",
        "                    'learning_rate': lr,\n",
        "                    'batch_size': bs,\n",
        "                    'num_epochs': epochs\n",
        "                }\n",
        "                # Optionally, save the best model state here\n",
        "                # torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "print(f\"\\nBest Validation Accuracy: {best_val_accuracy:.4f} with Hyperparameters: {best_hyperparameters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c36cde",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
